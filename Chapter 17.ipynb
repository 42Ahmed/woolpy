{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55560f8e",
   "metadata": {},
   "source": [
    "# Limited Dependent Variable Models and Sample Selection Corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb217e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wooldridge\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "from sklearn.metrics import accuracy_score\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce544337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  J.M. Wooldridge (2019) Introductory Econometrics: A Modern Approach,\n",
      "  Cengage Learning, 6th edition.\n",
      "\n",
      "  401k       401ksubs    admnrev       affairs     airfare\n",
      "  alcohol    apple       approval      athlet1     athlet2\n",
      "  attend     audit       barium        beauty      benefits\n",
      "  beveridge  big9salary  bwght         bwght2      campus\n",
      "  card       catholic    cement        census2000  ceosal1\n",
      "  ceosal2    charity     consump       corn        countymurders\n",
      "  cps78_85   cps91       crime1        crime2      crime3\n",
      "  crime4     discrim     driving       earns       econmath\n",
      "  elem94_95  engin       expendshares  ezanders    ezunem\n",
      "  fair       fertil1     fertil2       fertil3     fish\n",
      "  fringe     gpa1        gpa2          gpa3        happiness\n",
      "  hprice1    hprice2     hprice3       hseinv      htv\n",
      "  infmrt     injury      intdef        intqrt      inven\n",
      "  jtrain     jtrain2     jtrain3       kielmc      lawsch85\n",
      "  loanapp    lowbrth     mathpnl       meap00_01   meap01\n",
      "  meap93     meapsingle  minwage       mlb1        mroz\n",
      "  murder     nbasal      nyse          okun        openness\n",
      "  pension    phillips    pntsprd       prison      prminwge\n",
      "  rdchem     rdtelec     recid         rental      return\n",
      "  saving     sleep75     slp75_81      smoke       traffic1\n",
      "  traffic2   twoyear     volat         vote1       vote2\n",
      "  voucher    wage1       wage2         wagepan     wageprc\n",
      "  wine\n"
     ]
    }
   ],
   "source": [
    "wooldridge.data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d515963",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b67657e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mroz = wooldridge.data('mroz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402cb412",
   "metadata": {},
   "source": [
    "### 17.1 Married Women's Labor Force Participation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7850b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name of dataset: mroz\n",
      "no of variables: 22\n",
      "no of observations: 753\n",
      "\n",
      "+----------+---------------------------------+\n",
      "| variable | label                           |\n",
      "+----------+---------------------------------+\n",
      "| inlf     | =1 if in lab frce, 1975         |\n",
      "| hours    | hours worked, 1975              |\n",
      "| kidslt6  | # kids < 6 years                |\n",
      "| kidsge6  | # kids 6-18                     |\n",
      "| age      | woman's age in yrs              |\n",
      "| educ     | years of schooling              |\n",
      "| wage     | est. wage from earn, hrs        |\n",
      "| repwage  | rep. wage at interview in 1976  |\n",
      "| hushrs   | hours worked by husband, 1975   |\n",
      "| husage   | husband's age                   |\n",
      "| huseduc  | husband's years of schooling    |\n",
      "| huswage  | husband's hourly wage, 1975     |\n",
      "| faminc   | family income, 1975             |\n",
      "| mtr      | fed. marg. tax rte facing woman |\n",
      "| motheduc | mother's years of schooling     |\n",
      "| fatheduc | father's years of schooling     |\n",
      "| unem     | unem. rate in county of resid.  |\n",
      "| city     | =1 if live in SMSA              |\n",
      "| exper    | actual labor mkt exper          |\n",
      "| nwifeinc | (faminc - wage*hours)/1000      |\n",
      "| lwage    | log(wage)                       |\n",
      "| expersq  | exper^2                         |\n",
      "+----------+---------------------------------+\n",
      "\n",
      "T.A. Mroz (1987), “The Sensitivity of an Empirical Model of Married\n",
      "Women’s Hours of Work to Economic and Statistical Assumptions,”\n",
      "Econometrica 55, 765-799. Professor Ernst R. Berndt, of MIT, kindly\n",
      "provided the data, which he obtained from Professor Mroz.\n"
     ]
    }
   ],
   "source": [
    "wooldridge.data('mroz', description= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8121774c",
   "metadata": {},
   "source": [
    "Comparing between linear probability model, logit model and probit model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7042caf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Coef.  Std.Err.         z         P>|z|\n",
      "Intercept  0.585519  0.153580  3.812463  1.375890e-04\n",
      "nwifeinc  -0.003405  0.001558 -2.185242  2.887114e-02\n",
      "educ       0.037995  0.007340  5.176602  2.259636e-07\n",
      "exper      0.039492  0.005984  6.600115  4.108390e-11\n",
      "expersq   -0.000596  0.000199 -2.997303  2.723797e-03\n",
      "age       -0.016091  0.002415 -6.664002  2.664705e-11\n",
      "kidslt6   -0.261810  0.032152 -8.143000  3.856034e-16\n",
      "kidsge6    0.013012  0.013660  0.952558  3.408143e-01\n",
      "0.26421615770495754\n"
     ]
    }
   ],
   "source": [
    "model01 = smf.ols('inlf ~ nwifeinc + educ + exper + expersq + age + kidslt6 + kidsge6', data = mroz).fit(cov_type='HC3')\n",
    "print(model01.summary2().tables[1].iloc[:,:4])\n",
    "print(model01.rsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd3ee275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.533553\n",
      "         Iterations 6\n",
      "              Coef.  Std.Err.         z         P>|z|\n",
      "Intercept  0.425452  0.860370  0.494499  6.209535e-01\n",
      "nwifeinc  -0.021345  0.008421 -2.534620  1.125693e-02\n",
      "educ       0.221170  0.043440  5.091442  3.553503e-07\n",
      "exper      0.205870  0.032057  6.422001  1.344946e-10\n",
      "expersq   -0.003154  0.001016 -3.104093  1.908635e-03\n",
      "age       -0.088024  0.014573 -6.040232  1.538930e-09\n",
      "kidslt6   -1.443354  0.203585 -7.089692  1.344105e-12\n",
      "kidsge6    0.060112  0.074790  0.803749  4.215417e-01\n",
      "        Logit Marginal Effects       \n",
      "=====================================\n",
      "Dep. Variable:                   inlf\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "==============================================================================\n",
      "                dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "nwifeinc      -0.0038      0.001     -2.571      0.010      -0.007      -0.001\n",
      "educ           0.0395      0.007      5.414      0.000       0.025       0.054\n",
      "exper          0.0368      0.005      7.139      0.000       0.027       0.047\n",
      "expersq       -0.0006      0.000     -3.176      0.001      -0.001      -0.000\n",
      "age           -0.0157      0.002     -6.603      0.000      -0.020      -0.011\n",
      "kidslt6       -0.2578      0.032     -8.070      0.000      -0.320      -0.195\n",
      "kidsge6        0.0107      0.013      0.805      0.421      -0.015       0.037\n",
      "==============================================================================\n",
      "0.21968137484058814\n"
     ]
    }
   ],
   "source": [
    "model012 = smf.logit('inlf ~ nwifeinc + educ + exper + expersq + age + kidslt6 + kidsge6', data = mroz).fit()\n",
    "print(model012.summary2().tables[1].iloc[:,:4])\n",
    "print(logit_marg:= model012.get_margeff().summary())\n",
    "print(model012.prsquared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73782736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.532938\n",
      "         Iterations 5\n",
      "              Coef.  Std.Err.         z         P>|z|\n",
      "Intercept  0.270077  0.508593  0.531027  5.953999e-01\n",
      "nwifeinc  -0.012024  0.004840 -2.484327  1.297967e-02\n",
      "educ       0.130905  0.025254  5.183485  2.177783e-07\n",
      "exper      0.123348  0.018716  6.590348  4.387977e-11\n",
      "expersq   -0.001887  0.000600 -3.145205  1.659704e-03\n",
      "age       -0.052853  0.008477 -6.234656  4.527723e-10\n",
      "kidslt6   -0.868329  0.118522 -7.326287  2.366161e-13\n",
      "kidsge6    0.036005  0.043477  0.828142  4.075900e-01\n",
      "       Probit Marginal Effects       \n",
      "=====================================\n",
      "Dep. Variable:                   inlf\n",
      "Method:                          dydx\n",
      "At:                           overall\n",
      "==============================================================================\n",
      "                dy/dx    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "nwifeinc      -0.0036      0.001     -2.509      0.012      -0.006      -0.001\n",
      "educ           0.0394      0.007      5.452      0.000       0.025       0.054\n",
      "exper          0.0371      0.005      7.200      0.000       0.027       0.047\n",
      "expersq       -0.0006      0.000     -3.205      0.001      -0.001      -0.000\n",
      "age           -0.0159      0.002     -6.739      0.000      -0.021      -0.011\n",
      "kidslt6       -0.2612      0.032     -8.197      0.000      -0.324      -0.199\n",
      "kidsge6        0.0108      0.013      0.829      0.407      -0.015       0.036\n",
      "==============================================================================\n",
      "0.2205805437252938\n"
     ]
    }
   ],
   "source": [
    "model013 = smf.probit('inlf ~ nwifeinc + educ + exper + expersq + age + kidslt6 + kidsge6', data = mroz).fit()\n",
    "print(model013.summary2().tables[1].iloc[:,:4])\n",
    "print(probit_marg:= model013.get_margeff().summary())\n",
    "print(model013.prsquared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc292079",
   "metadata": {},
   "source": [
    "To get percentage predicted correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a938c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7343957503320053, 0.7357237715803453, 0.7343957503320053)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = mroz['inlf']\n",
    "\n",
    "acc_lpm = accuracy_score(y, (model01.predict(mroz) >= 0.5).astype(int))\n",
    "acc_logit = accuracy_score(y, (model012.predict(mroz) >= 0.5).astype(int))\n",
    "acc_probit = accuracy_score(y, (model013.predict(mroz) >= 0.5).astype(int))\n",
    "\n",
    "acc_lpm, acc_logit, acc_probit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e1c119f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================\n",
      "                      LPM (OLS) Logit (MLE) Probit (MLE)\n",
      "--------------------------------------------------------\n",
      "Intercept             0.586***  0.425       0.270       \n",
      "                      (0.154)   (0.860)     (0.509)     \n",
      "nwifeinc              -0.003**  -0.021**    -0.012**    \n",
      "                      (0.002)   (0.008)     (0.005)     \n",
      "educ                  0.038***  0.221***    0.131***    \n",
      "                      (0.007)   (0.043)     (0.025)     \n",
      "exper                 0.039***  0.206***    0.123***    \n",
      "                      (0.006)   (0.032)     (0.019)     \n",
      "expersq               -0.001*** -0.003***   -0.002***   \n",
      "                      (0.000)   (0.001)     (0.001)     \n",
      "age                   -0.016*** -0.088***   -0.053***   \n",
      "                      (0.002)   (0.015)     (0.008)     \n",
      "kidslt6               -0.262*** -1.443***   -0.868***   \n",
      "                      (0.032)   (0.204)     (0.119)     \n",
      "kidsge6               0.013     0.060       0.036       \n",
      "                      (0.014)   (0.075)     (0.043)     \n",
      "% Correct             73.4      73.6        73.4        \n",
      "Fit (R² or Pseudo R²) 0.264     0.220       0.221       \n",
      "Log-Lik               -423.89   -401.77     -401.30     \n",
      "========================================================\n",
      "Standard errors in parentheses.\n",
      "* p<.1, ** p<.05, ***p<.01\n"
     ]
    }
   ],
   "source": [
    "# Generate table\n",
    "results_table = summary_col(\n",
    "    [model01, model012, model013],\n",
    "    stars=True,\n",
    "    float_format=\"%.3f\",\n",
    "    model_names=[\"LPM (OLS)\", \"Logit (MLE)\", \"Probit (MLE)\"],\n",
    "    info_dict={\n",
    "        \"Fit (R² or Pseudo R²)\": lambda x: f\"{x.rsquared:.3f}\" if hasattr(x, \"rsquared\") else f\"{x.prsquared:.3f}\",\n",
    "        \"Log-Lik\": lambda x: f\"{x.llf:.2f}\" if hasattr(x, \"llf\") else \"\",\n",
    "        \"% Correct\": lambda x: f\"{100 * accuracy_score(y, (x.predict(mroz) >= 0.5).astype(int)):.1f}\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Get string output and filter out unwanted lines\n",
    "table_str = results_table.as_text()\n",
    "filtered_str = \"\\n\".join(\n",
    "    line for line in table_str.splitlines()\n",
    "    if not re.search(r\"R-squared|Adj. R-squared\", line)\n",
    ")\n",
    "\n",
    "# Print cleaned-up table\n",
    "print(filtered_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e9f6d0",
   "metadata": {},
   "source": [
    "The three models agree on the statistically significant variables. But the coefficients are not comparable. Use marginal effect for logit and probit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e291068e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LPM (OLS)</th>\n",
       "      <th>Logit (Marg Eff)</th>\n",
       "      <th>Probit (Marg Eff)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nwifeinc</th>\n",
       "      <td>-0.0034</td>\n",
       "      <td>-0.0038</td>\n",
       "      <td>-0.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>educ</th>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exper</th>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.0371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expersq</th>\n",
       "      <td>-0.0006</td>\n",
       "      <td>-0.0006</td>\n",
       "      <td>-0.0006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.0161</td>\n",
       "      <td>-0.0157</td>\n",
       "      <td>-0.0159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kidslt6</th>\n",
       "      <td>-0.2618</td>\n",
       "      <td>-0.2578</td>\n",
       "      <td>-0.2612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kidsge6</th>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0108</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          LPM (OLS) Logit (Marg Eff) Probit (Marg Eff)\n",
       "nwifeinc    -0.0034          -0.0038           -0.0036\n",
       "educ         0.0380           0.0395            0.0394\n",
       "exper        0.0395           0.0368            0.0371\n",
       "expersq     -0.0006          -0.0006           -0.0006\n",
       "age         -0.0161          -0.0157           -0.0159\n",
       "kidslt6     -0.2618          -0.2578           -0.2612\n",
       "kidsge6      0.0130           0.0107            0.0108"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tab0 = model01.summary2().tables[1].iloc[1:,0].round(4)\n",
    "tab0.name = \"LPM (OLS)\"\n",
    "\n",
    "tab1 = logit_marg.tables[1]\n",
    "tab1 = pd.DataFrame(tab1)\n",
    "tab1 = tab1.iloc[1:,1]\n",
    "tab1.index = tab0.index\n",
    "tab1.name = \"Logit (Marg Eff)\"\n",
    "\n",
    "tab2 = probit_marg.tables[1]\n",
    "tab2 = pd.DataFrame(tab2)\n",
    "tab2 = tab2.iloc[1:,1]\n",
    "tab2.index = tab0.index\n",
    "tab2.name = \"Probit (Marg Eff)\"\n",
    "\n",
    "\n",
    "pd.concat([tab0, tab1, tab2], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b86fb0",
   "metadata": {},
   "source": [
    "Interpreting logistic regression :coefficients and marginal effects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3631f92",
   "metadata": {},
   "source": [
    "coefficient of educ = 0.2212:  \n",
    "A one year increase in education is associated with a 0.2212 unit increase in the log odds of a woman participating in the labor force\n",
    "\n",
    "APE of educ = 0.0395:  \n",
    "A one year increase in education is associated with a 3.95 percentage point increase in probability of labor force participation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4174b70a",
   "metadata": {},
   "source": [
    "interpreting kidslt6, LPM vs Probit  \n",
    "in LPM model, having one more kid less than 6 years old is estimated to reduce probability of labor force participation by 0.262 percentage point regardless of number of kids.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32f408c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "kid0 = {\n",
    "    'nwifeinc': 20.13,\n",
    "    'educ': 12.3,\n",
    "    'exper': 10.6,\n",
    "    'expersq': 10.6**2,\n",
    "    'age': 42.5,\n",
    "    'kidsge6': 1,\n",
    "    'kidslt6': 0\n",
    "}\n",
    "kid1 = kid0.copy()\n",
    "kid1['kidslt6'] = 1\n",
    "\n",
    "kid2 = kid0.copy()\n",
    "kid2['kidslt6'] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d89da27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0    0.699647\n",
       " 1    0.365069\n",
       " 2    0.112513\n",
       " dtype: float64,\n",
       " np.float64(-0.33457838066203827),\n",
       " np.float64(-0.252555628152638))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs = model013.predict(pd.DataFrame([kid0, kid1, kid2]))\n",
    "\n",
    "prob_lost1 = probs.iloc[1] - probs.iloc[0]\n",
    "prob_lost2 = probs.iloc[2] - probs.iloc[1] \n",
    "\n",
    "probs, prob_lost1, prob_lost2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ef1fd5",
   "metadata": {},
   "source": [
    "Probit model takes into account actual values of the person. So a woman with $nwifeinc = 20.13, educ = 12.3, exper = 10.6, age = 42.5, kidge6 =1$ and went from 0 to 1 small child will get probability of labour force participation lower by 0.334  \n",
    "If the woman goes from 1 small child to 2, probability decreases again by 0.256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dacc99",
   "metadata": {},
   "source": [
    "### 17.2 Married Women's Annual Labor Supply "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
